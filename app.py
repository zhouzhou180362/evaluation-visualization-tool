import os
import io
import shutil
import uuid
import subprocess
from typing import Dict, Tuple, Optional, List

# ä¾èµ–æ£€æŸ¥å’Œå¤‡ç”¨æ–¹æ¡ˆ
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    st.error("âš ï¸ pandasæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    st.error("âš ï¸ numpyæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")

try:
    import openpyxl
    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False
    st.error("âš ï¸ openpyxlæœªå®‰è£…ï¼ŒExcelæ–‡ä»¶å¤„ç†åŠŸèƒ½å—é™")

# å›¾è¡¨åº“é€‰æ‹©
CHART_LIBRARY = None
try:
    import plotly.graph_objects as go
    import plotly.express as px
    CHART_LIBRARY = "plotly"
except ImportError:
    try:
        import matplotlib.pyplot as plt
        from matplotlib import font_manager as fm
        CHART_LIBRARY = "matplotlib"
    except ImportError:
        CHART_LIBRARY = "none"
        st.warning("âš ï¸ å›¾è¡¨åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ–‡æœ¬ç»Ÿè®¡")

import streamlit as st


# ========= åŸºç¡€é…ç½® =========
WORKSPACE_ROOT = os.path.abspath(os.path.dirname(__file__))

PROCESSING_TYPES: Dict[str, str] = {
    "é—®ç­”æå–": os.path.join(WORKSPACE_ROOT, "é—®ç­”æå–", "1.py"),
    "ç¿»è¯‘æå–": os.path.join(WORKSPACE_ROOT, "ç¿»è¯‘æå–", "1.py"),
    "è§£é‡Šä»£ç æå–": os.path.join(WORKSPACE_ROOT, "è§£é‡Šä»£ç æå–", "1.py"),
    "å‘½ä»¤ç›¸å…³æå–": os.path.join(WORKSPACE_ROOT, "å‘½ä»¤ç›¸å…³æå–", "1.py"),
    "ä»£ç ç”Ÿæˆæå–": os.path.join(WORKSPACE_ROOT, "ä»£ç ç”Ÿæˆæå–", "1.py"),
    "ä»£ç çº é”™æå–": os.path.join(WORKSPACE_ROOT, "ä»£ç çº é”™æå–", "1.py"),
    "ä»£ç è¡¥å…¨æå–": os.path.join(WORKSPACE_ROOT, "ä»£ç è¡¥å…¨æå–", "1.py"),
    "è®¡ç®—æœºçŸ¥è¯†æå–": os.path.join(WORKSPACE_ROOT, "è®¡ç®—æœºçŸ¥è¯†æå–", "1.py"),
}


def ensure_exists(path: str):
    os.makedirs(path, exist_ok=True)


def ensure_cjk_font():
    """ä¸º Matplotlib è®¾ç½®å¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œé¿å…ä¸­æ–‡æ˜¾ç¤ºä¸ºæ–¹å—ã€‚"""
    try:
        candidates = [
            "PingFang SC",  # macOS é»˜è®¤ä¸­æ–‡
            "Heiti SC",
            "STHeiti",
            "Songti SC",
            "Hiragino Sans GB",
            "Noto Sans CJK SC",
            "Microsoft YaHei",
            "SimHei",
        ]
        available = {f.name for f in fm.fontManager.ttflist}
        chosen = None
        for name in candidates:
            if name in available:
                chosen = name
                break
        if chosen:
            plt.rcParams["font.sans-serif"] = [chosen]
            plt.rcParams["font.family"] = "sans-serif"
        # è§£å†³åæ ‡è½´è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
        plt.rcParams["axes.unicode_minus"] = False
    except Exception:
        # å®‰é™å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
        pass


def save_uploaded_file(uploaded_file, dest_dir: str) -> str:
    ensure_exists(dest_dir)
    dest_path = os.path.join(dest_dir, uploaded_file.name)
    with open(dest_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return dest_path


def run_script_with_temp_cwd(script_path: str, input_xlsx_path: str, run_dir: str) -> Tuple[str, str]:
    """
    åœ¨ run_dir ç›®å½•ä¸‹æ‰§è¡Œè„šæœ¬ script_pathï¼š
    - å°† input_xlsx_path å¤åˆ¶åˆ° run_dir
    - ä»¥ run_dir ä¸ºå·¥ä½œç›®å½•è¿è¡Œè„šæœ¬ï¼ˆè„šæœ¬ä¼šè‡ªåŠ¨å‘ç° .xlsx å¹¶è¾“å‡º _multi_sheets.xlsxï¼‰
    è¿”å› (è¾“å‡ºæ–‡ä»¶ç»å¯¹è·¯å¾„, è„šæœ¬æ ‡å‡†è¾“å‡º)
    """
    ensure_exists(run_dir)
    local_input = os.path.join(run_dir, os.path.basename(input_xlsx_path))
    if os.path.abspath(local_input) != os.path.abspath(input_xlsx_path):
        shutil.copy2(input_xlsx_path, local_input)

    # å¤åˆ¶ä¾èµ–æ–‡ä»¶åˆ°è„šæœ¬ç›®å½•
    script_dir = os.path.dirname(script_path)
    deps_file = os.path.join(script_dir, "deps.py")
    if os.path.exists(deps_file):
        shutil.copy2(deps_file, run_dir)

    env = os.environ.copy()
    # è®¾ç½®Pythonè·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°ä¾èµ–åŒ…
    env["PYTHONPATH"] = f"{WORKSPACE_ROOT}:{run_dir}"
    
    python_exec = env.get("PYTHON_EXECUTABLE", None) or "python3"
    completed = subprocess.run(
        [python_exec, script_path],
        cwd=run_dir,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        check=False,
        text=True,
        env=env,
    )
    stdout = completed.stdout

    # åœ¨ run_dir ä¸­å¯»æ‰¾è¾“å‡º *_multi_sheets*.xlsx
    out_files = [
        os.path.join(run_dir, f)
        for f in os.listdir(run_dir)
        if f.lower().endswith(".xlsx") and "_multi_sheets" in f
    ]
    if not out_files:
        raise RuntimeError(f"è„šæœ¬æœªäº§å‡ºç»“æœ Excelã€‚è¾“å‡ºæ—¥å¿—å¦‚ä¸‹:\n{stdout}")
    # å–ä¿®æ”¹æ—¶é—´æœ€æ–°çš„
    out_files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return out_files[0], stdout


def load_last_sheet_and_penultimate_column(xlsx_path: str) -> Tuple[pd.DataFrame, str, pd.Series]:
    """
    åŠ è½½ç»“æœ Excel çš„æœ€åä¸€ä¸ª Sheetï¼Œè¿”å› (æœ€åSheetçš„DataFrame, å€’æ•°ç¬¬äºŒåˆ—åˆ—å, è¯¥åˆ—Series)
    è‹¥åˆ—æ•° < 2 åˆ™æŠ›é”™ã€‚
    """
    try:
        xls = pd.ExcelFile(xlsx_path, engine="openpyxl")
    except Exception as e:
        raise RuntimeError(f"è¯»å–ç»“æœ Excel å¤±è´¥ï¼š{e}")

    if not xls.sheet_names:
        raise RuntimeError("ç»“æœ Excel ä¸åŒ…å«ä»»ä½• Sheet")
    last_sheet_name = xls.sheet_names[-1]
    df = pd.read_excel(xls, sheet_name=last_sheet_name, engine="openpyxl")
    if df.shape[1] < 2:
        raise RuntimeError(f"æœ€åä¸€ä¸ª Sheet â€˜{last_sheet_name}â€™ çš„åˆ—æ•°ä¸è¶³ï¼Œæ— æ³•å®šä½å€’æ•°ç¬¬äºŒåˆ—")
    penultimate_col = df.columns[-2]
    return df, penultimate_col, df.iloc[:, -2]


def compare_two_results(
    xlsx1: str,
    xlsx2: str,
    align_mode: str = "row",
    key_column: Optional[str] = None,
    join_strategy: str = "left",
    processing_type: Optional[str] = None,
    ge_threshold: float = 7.0,
    avg_round_decimals: int = 2,
) -> Tuple[pd.DataFrame, pd.DataFrame, bytes, pd.DataFrame, pd.DataFrame]:
    """
    åŸºäºä¸¤ä¸ªç»“æœ Excelï¼ˆæœ€åä¸€ä¸ª Sheet çš„å€’æ•°ç¬¬äºŒåˆ—ï¼‰è¿›è¡Œå¯¹æ¯”ã€‚
    è¿”å›ï¼š(å¯¹æ¯”æ˜ç»† DataFrame, æ±‡æ€»ç»Ÿè®¡ DataFrame, å›¾è¡¨PNGå­—èŠ‚)
    """
    df1, col1_name, s1 = load_last_sheet_and_penultimate_column(xlsx1)
    df2, col2_name, s2 = load_last_sheet_and_penultimate_column(xlsx2)

    detail_rows: List[Dict] = []

    def compare_values(v1, v2) -> Tuple[str, Optional[float], Optional[str]]:
        n1 = pd.to_numeric(pd.Series([v1]), errors="coerce").iloc[0]
        n2 = pd.to_numeric(pd.Series([v2]), errors="coerce").iloc[0]
        abnormal: Optional[str] = None
        if pd.isna(n1) or pd.isna(n2):
            return "N/A", np.nan, "å€¼æ— æ³•è½¬ä¸ºæ•°å€¼æˆ–ç¼ºå¤±"

        diff = float(n1 - n2)

        # ç‰¹æ®Šé€»è¾‘ï¼šé—®ç­”æå– æŒ‰ Excel è§„åˆ™
        if processing_type == "é—®ç­”æå–":
            # åŸå§‹ Excel è§„åˆ™ï¼š
            # =IF(A2=B2,"S",IF(ABS(A2-B2)>1,IF(A2>B2,"A","B"),IF(OR(ABS(A2-B2)=1,ABS(A2-B2)=0),"S"&IF(A2>B2,"A","B"),"B")))
            if n1 == n2:
                base = "S"
            else:
                ad = abs(n1 - n2)
                if ad > 1:
                    base = "A" if n1 > n2 else "B"
                elif ad == 1 or ad == 0:
                    base = "S" + ("A" if n1 > n2 else "B")
                else:
                    base = "B"
            mapping = {"A": "G", "SA": "SG", "S": "S", "SB": "SB", "B": "B"}
            tag = mapping.get(base, "S")
            return tag, diff, abnormal

        # é»˜è®¤é€»è¾‘ï¼šG/S/B
        if n1 > n2:
            tag = "G"
        elif n1 == n2:
            tag = "S"
        else:
            tag = "B"
        return tag, diff, abnormal

    if align_mode == "row":
        len1, len2 = len(df1), len(df2)
        max_len = max(len1, len2)
        for i in range(max_len):
            v1 = s1.iloc[i] if i < len1 else np.nan
            v2 = s2.iloc[i] if i < len2 else np.nan
            tag, diff, abnormal = compare_values(v1, v2)
            if i >= len1 or i >= len2:
                abnormal = (abnormal + "; " if abnormal else "") + "ä¸¤æ–‡ä»¶è¡Œæ•°ä¸ä¸€è‡´"
            detail_rows.append({
                "è¡Œç´¢å¼•": i,
                "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                "å·®å€¼(å€¼1-å€¼2)": diff,
                "æ ‡è®°": tag,
                "å¼‚å¸¸è¯´æ˜": abnormal,
            })
    else:
        if not key_column:
            raise RuntimeError("é€‰æ‹©é”®å¯¹é½æ—¶å¿…é¡»æä¾›é”®åˆ—å")
        if key_column not in df1.columns:
            raise RuntimeError(f"æ–‡ä»¶1ç¼ºå°‘é”®åˆ— â€˜{key_column}â€™")
        if key_column not in df2.columns:
            raise RuntimeError(f"æ–‡ä»¶2ç¼ºå°‘é”®åˆ— â€˜{key_column}â€™")

        a = df1[[key_column]].copy()
        a["__v1"] = s1.values
        b = df2[[key_column]].copy()
        b["__v2"] = s2.values

        # ä¸»ä½“å¯¹é½
        if join_strategy == "inner":
            keys = sorted(set(a[key_column]).intersection(set(b[key_column])))
        else:  # leftï¼ˆä»¥æ–‡ä»¶1ä¸ºä¸»ï¼‰
            keys = list(a[key_column])

        a_map = dict(zip(a[key_column], a["__v1"]))
        b_map = dict(zip(b[key_column], b["__v2"]))

        for k in dict.fromkeys(keys):
            v1 = a_map.get(k, np.nan)
            v2 = b_map.get(k, np.nan)
            tag, diff, abnormal = compare_values(v1, v2)
            if k not in a_map or k not in b_map:
                abnormal = (abnormal + "; " if abnormal else "") + "é”®æœªåŒ¹é…"
            detail_rows.append({
                "é”®": k,
                "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                "å·®å€¼(å€¼1-å€¼2)": diff,
                "æ ‡è®°": tag,
                "å¼‚å¸¸è¯´æ˜": abnormal,
            })

        # ç»Ÿè®¡ inner æƒ…å†µä¸‹æœªèƒ½åŒ¹é…ä½†éœ€è¦è®°ä¸ºå¼‚å¸¸çš„é”®
        if join_strategy == "inner":
            only_in_a = set(a[key_column]) - set(b[key_column])
            for k in sorted(only_in_a):
                v1 = a_map.get(k, np.nan)
                detail_rows.append({
                    "é”®": k,
                    "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                    "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": np.nan,
                    "å·®å€¼(å€¼1-å€¼2)": np.nan,
                    "æ ‡è®°": "N/A",
                    "å¼‚å¸¸è¯´æ˜": "é”®æœªåŒ¹é…(ä»…æ–‡ä»¶1)",
                })
            only_in_b = set(b[key_column]) - set(a[key_column])
            for k in sorted(only_in_b):
                v2 = b_map.get(k, np.nan)
                detail_rows.append({
                    "é”®": k,
                    "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": np.nan,
                    "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                    "å·®å€¼(å€¼1-å€¼2)": np.nan,
                    "æ ‡è®°": "N/A",
                    "å¼‚å¸¸è¯´æ˜": "é”®æœªåŒ¹é…(ä»…æ–‡ä»¶2)",
                })

    detail_df = pd.DataFrame(detail_rows)
    # æ±‡æ€»
    total = len(detail_df)
    # æ±‡æ€»ç»Ÿè®¡ï¼šé—®ç­”æå–åœºæ™¯åŒ…å«SGå’ŒSBï¼Œå…¶ä»–åœºæ™¯æŒ‰G/S/Bèšåˆ
    if processing_type == "é—®ç­”æå–":
        # é—®ç­”æå–åœºæ™¯ï¼šåŒ…å«SGå’ŒSB
        counts = detail_df["æ ‡è®°"].value_counts(dropna=False).reindex(["G", "SG", "S", "SB", "B", "N/A"], fill_value=0)
        summary_df = pd.DataFrame({
            "ç±»åˆ«": ["G", "SG", "S", "SB", "B", "N/A"],
            "æ•°é‡": [int(counts.get(x, 0)) for x in ["G", "SG", "S", "SB", "B", "N/A"]],
        })
        summary_df["å æ¯”"] = summary_df["æ•°é‡"].apply(lambda x: f"{(x / total * 100) if total else 0:.2f}%")
    else:
        # å…¶ä»–åœºæ™¯ï¼šSG/SBå½’å…¥S
        def base_bucket(x: str) -> str:
            if x == "N/A":
                return "N/A"
            if x in ("G", "S", "B"):
                return x
            if x in ("SG", "SB"):
                return "S"
            return x

        counts = detail_df["æ ‡è®°"].map(base_bucket).value_counts(dropna=False).reindex(["G", "S", "B", "N/A"], fill_value=0)
        summary_df = pd.DataFrame({
            "ç±»åˆ«": ["G", "S", "B", "N/A"],
            "æ•°é‡": [int(counts.get(x, 0)) for x in ["G", "S", "B", "N/A"]],
        })
        summary_df["å æ¯”"] = summary_df["æ•°é‡"].apply(lambda x: f"{(x / total * 100) if total else 0:.2f}%")
    # å¯é™„åŠ åŸºç¡€æŒ‡æ ‡
    try:
        numeric_diff = pd.to_numeric(detail_df["å·®å€¼(å€¼1-å€¼2)"], errors="coerce")
        mean1 = pd.to_numeric(detail_df["å€¼1(å€’æ•°ç¬¬äºŒåˆ—)"], errors="coerce").mean()
        mean2 = pd.to_numeric(detail_df["å€¼2(å€’æ•°ç¬¬äºŒåˆ—)"], errors="coerce").mean()
        diff_mean = numeric_diff.mean()
    except Exception:
        mean1 = mean2 = diff_mean = np.nan

    extra_rows = pd.DataFrame([
        {"ç±»åˆ«": "å€¼1å‡å€¼", "æ•°é‡": mean1, "å æ¯”": "-"},
        {"ç±»åˆ«": "å€¼2å‡å€¼", "æ•°é‡": mean2, "å æ¯”": "-"},
        {"ç±»åˆ«": "å·®å€¼å‡å€¼", "æ•°é‡": diff_mean, "å æ¯”": "-"},
    ])
    summary_df = pd.concat([summary_df, extra_rows], ignore_index=True)

    # ç”Ÿæˆå›¾è¡¨
    buf = io.BytesIO()
    
    if CHART_LIBRARY == "plotly":
        # ä½¿ç”¨Plotlyç”Ÿæˆå›¾è¡¨
        if processing_type == "é—®ç­”æå–":
            detailed_counts = detail_df["æ ‡è®°"].value_counts(dropna=False)
            cats = ["G", "SG", "S", "SB", "B"]
            values = [int(detailed_counts.get(c, 0)) for c in cats]
            colors = ["#4CAF50", "#81C784", "#2196F3", "#FFB74D", "#F44336"]
            
            fig = go.Figure(data=[
                go.Bar(x=cats, y=values, marker_color=colors)
            ])
            fig.update_layout(
                title="G/SG/S/SB/B æ•°é‡åˆ†å¸ƒ",
                xaxis_title="ç±»åˆ«",
                yaxis_title="æ•°é‡",
                height=400
            )
        else:
            fig = go.Figure(data=[
                go.Bar(x=["G", "S", "B"], 
                      y=[counts.get("G", 0), counts.get("S", 0), counts.get("B", 0)],
                      marker_color=["#4CAF50", "#2196F3", "#F44336"])
            ])
            fig.update_layout(
                title="G/S/B æ•°é‡åˆ†å¸ƒ",
                xaxis_title="ç±»åˆ«",
                yaxis_title="æ•°é‡",
                height=400
            )
        
        # ä¿å­˜ä¸ºPNG
        fig.write_image(buf, format="png", width=600, height=400)
        
    elif CHART_LIBRARY == "matplotlib":
        # ä½¿ç”¨Matplotlibç”Ÿæˆå›¾è¡¨
        ensure_cjk_font()
        fig, ax = plt.subplots(figsize=(6, 3))
        if processing_type == "é—®ç­”æå–":
            detailed_counts = detail_df["æ ‡è®°"].value_counts(dropna=False)
            cats = ["G", "SG", "S", "SB", "B"]
            values = [int(detailed_counts.get(c, 0)) for c in cats]
            colors = ["#4CAF50", "#81C784", "#2196F3", "#FFB74D", "#F44336"]
            ax.bar(cats, values, color=colors)
            ax.set_title("G/SG/S/SB/B æ•°é‡åˆ†å¸ƒ")
        else:
            ax.bar(["G", "S", "B"], [counts.get("G", 0), counts.get("S", 0), counts.get("B", 0)], color=["#4CAF50", "#2196F3", "#F44336"]) 
            ax.set_title("G/S/B æ•°é‡åˆ†å¸ƒ")
        ax.set_ylabel("æ•°é‡")
        plt.tight_layout()
        fig.savefig(buf, format="png", dpi=200)
        plt.close(fig)
        
    else:
        # æ— å›¾è¡¨åº“ï¼Œç”Ÿæˆæ–‡æœ¬ç»Ÿè®¡
        st.warning("å›¾è¡¨åº“ä¸å¯ç”¨ï¼Œæ˜¾ç¤ºæ–‡æœ¬ç»Ÿè®¡")
        buf = None
    
    if buf:
        buf.seek(0)

    # ============== æ–°å¢ï¼šåˆ—çº§ç»Ÿè®¡ï¼ˆç¬¬2åˆ—..å€’æ•°ç¬¬2åˆ—ï¼‰ ==============
    def compute_column_stats(df_a: pd.DataFrame, df_b: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        cols_a = list(df_a.columns)
        cols_b = list(df_b.columns)
        rng_a = cols_a[1:-1] if len(cols_a) >= 3 else []
        rng_b = cols_b[1:-1] if len(cols_b) >= 3 else []
        max_len = max(len(rng_a), len(rng_b))

        mean_rows: List[Dict] = []
        thresh_rows: List[Dict] = []

        for i in range(max_len):
            name_a = rng_a[i] if i < len(rng_a) else None
            name_b = rng_b[i] if i < len(rng_b) else None

            s_a = df_a[name_a] if name_a is not None else pd.Series(dtype=float)
            s_b = df_b[name_b] if name_b is not None else pd.Series(dtype=float)

            num_a = pd.to_numeric(s_a, errors="coerce")
            num_b = pd.to_numeric(s_b, errors="coerce")

            valid_a = num_a.dropna()
            valid_b = num_b.dropna()

            abnormal_notes: List[str] = []
            if name_a is None:
                abnormal_notes.append("æ–‡ä»¶1ç¼ºå°‘å¯¹åº”åˆ—")
            if name_b is None:
                abnormal_notes.append("æ–‡ä»¶2ç¼ºå°‘å¯¹åº”åˆ—")
            if valid_a.empty:
                abnormal_notes.append("æ–‡ä»¶1æ— æœ‰æ•ˆæ•°å€¼")
            if valid_b.empty:
                abnormal_notes.append("æ–‡ä»¶2æ— æœ‰æ•ˆæ•°å€¼")

            mean_a = round(float(valid_a.mean()), avg_round_decimals) if not valid_a.empty else np.nan
            mean_b = round(float(valid_b.mean()), avg_round_decimals) if not valid_b.empty else np.nan
            mean_diff = round(mean_a - mean_b, avg_round_decimals) if not (pd.isna(mean_a) or pd.isna(mean_b)) else np.nan

            mean_rows.append({
                "åˆ—åº": i + 2,
                "æ–‡ä»¶1åˆ—å": name_a,
                "æ–‡ä»¶2åˆ—å": name_b,
                "æ–‡ä»¶1å‡å€¼": mean_a if not pd.isna(mean_a) else "N/A",
                "æ–‡ä»¶2å‡å€¼": mean_b if not pd.isna(mean_b) else "N/A",
                "å·®å€¼(å‡å€¼1-å‡å€¼2)": mean_diff if not pd.isna(mean_diff) else "N/A",
                "å¼‚å¸¸è¯´æ˜": "; ".join(abnormal_notes) if abnormal_notes else None,
            })

            # é˜ˆå€¼è®¡æ•°
            cnt_a = int((valid_a >= ge_threshold).sum()) if not valid_a.empty else 0
            cnt_b = int((valid_b >= ge_threshold).sum()) if not valid_b.empty else 0
            diff_cnt = cnt_a - cnt_b
            
            # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆç›¸å¯¹äºæœ‰æ•ˆæ•°æ®æ•°é‡ï¼‰
            pct_cnt_a = f"{(cnt_a / len(valid_a) * 100) if len(valid_a) else 0:.2f}%"
            pct_cnt_b = f"{(cnt_b / len(valid_b) * 100) if len(valid_b) else 0:.2f}%"

            thresh_rows.append({
                "åˆ—åº": i + 2,
                "æ–‡ä»¶1åˆ—å": name_a,
                "æ–‡ä»¶2åˆ—å": name_b,
                "é˜ˆå€¼(>=)": ge_threshold,
                "æ–‡ä»¶1è®¡æ•°": cnt_a,
                "æ–‡ä»¶1è®¡æ•°å æ¯”": pct_cnt_a,
                "æ–‡ä»¶2è®¡æ•°": cnt_b,
                "æ–‡ä»¶2è®¡æ•°å æ¯”": pct_cnt_b,
                "å·®å€¼(è®¡æ•°1-è®¡æ•°2)": diff_cnt,
                "å¼‚å¸¸è¯´æ˜": "; ".join(abnormal_notes) if abnormal_notes else None,
            })

        return pd.DataFrame(mean_rows), pd.DataFrame(thresh_rows)

    column_avg_df, threshold_df = compute_column_stats(df1, df2)

    return detail_df, summary_df, buf.read(), column_avg_df, threshold_df


def build_comparison_excel(detail_df: pd.DataFrame, summary_df: pd.DataFrame, save_dir: str,
                           column_avg_df: Optional[pd.DataFrame] = None,
                           threshold_df: Optional[pd.DataFrame] = None) -> str:
    ensure_exists(save_dir)
    out_path = os.path.join(save_dir, "å¯¹æ¯”ç»Ÿè®¡ç»“æœ.xlsx")
    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        detail_df.to_excel(writer, index=False, sheet_name="å¯¹æ¯”æ˜ç»†")
        summary_df.to_excel(writer, index=False, sheet_name="æ±‡æ€»ç»Ÿè®¡")
        if column_avg_df is not None:
            column_avg_df.to_excel(writer, index=False, sheet_name="åˆ—çº§å‡å€¼ç»Ÿè®¡")
        if threshold_df is not None:
            threshold_df.to_excel(writer, index=False, sheet_name="åˆ—çº§é˜ˆå€¼è®¡æ•°")
    return out_path


def main_page():
    st.set_page_config(page_title="è‡ªåŠ¨åŒ–è¯„æµ‹å¯è§†åŒ–å·¥å…·", layout="wide", page_icon="ğŸ“Š")
    st.title("è‡ªåŠ¨åŒ–è¯„æµ‹å¯è§†åŒ–å·¥å…·")

    with st.sidebar:
        st.markdown("**ä½¿ç”¨æµç¨‹**")
        st.markdown("1. é€‰æ‹©å¤„ç†ç±»å‹\n2. ä¸Šä¼  1 æˆ– 2 ä¸ª Excel\n3. é€‰æ‹©å¯¹é½æ–¹å¼ï¼ˆå¯é€‰ï¼‰\n4. ç‚¹å‡»å¼€å§‹å¤„ç†")

    st.subheader("é€‰æ‹©å¤„ç†ç±»å‹")
    type_name = st.selectbox("å¤„ç†ç±»å‹", list(PROCESSING_TYPES.keys()))
    st.caption("æ¯ç§ç±»å‹å¯¹åº”ä¸€ä¸ªå·²æœ‰ Python è„šæœ¬ï¼Œå°†åœ¨æœ¬åœ°è¿è¡Œç”Ÿæˆç»“æœ Excelã€‚")

    st.subheader("ä¸Šä¼ æ–‡ä»¶")
    uploads = st.file_uploader("ä¸Šä¼  1 æˆ– 2 ä¸ª Excel æ–‡ä»¶ (.xlsx)", type=["xlsx"], accept_multiple_files=True)
    if uploads and len(uploads) > 2:
        st.error("æœ€å¤šåªèƒ½ä¸Šä¼  2 ä¸ªæ–‡ä»¶")
        return

    st.subheader("å¯¹é½æ–¹å¼ï¼ˆå¯é€‰å¢å¼ºï¼‰")
    align_mode = st.radio("å¯¹é½æ¨¡å¼", options=["æŒ‰è¡Œåº", "æŒ‰é”®åˆ—å¯¹é½"], index=0, horizontal=True)
    key_col = None
    join_strategy = "left"
    if align_mode == "æŒ‰é”®åˆ—å¯¹é½":
        key_col = st.text_input("é”®åˆ—åï¼ˆä¸¤ä¸ªç»“æœè¡¨çš„æœ€åä¸€ä¸ª Sheet ä¸­éœ€åŒ…å«æ­¤åˆ—ï¼‰")
        join_strategy = st.selectbox("å¯¹é½ç­–ç•¥", options=["left", "inner"], index=0, help="left: ä»¥æ–‡ä»¶1ä¸ºä¸»ï¼›inner: ä»…åŒ¹é…åˆ°çš„é”®ï¼Œä½†æœªåŒ¹é…é”®ä¹Ÿä¼šè®°ä¸ºå¼‚å¸¸è¡Œ")

    st.subheader("å…¶ä»–")
    preview_rows = st.slider("é¢„è§ˆè¡Œæ•°ï¼ˆæœ€åä¸€ä¸ª Sheet æˆ–å¯¹æ¯”æ˜ç»†ï¼‰", min_value=5, max_value=200, value=50, step=5)

    run = st.button("å¼€å§‹å¤„ç†/è¿è¡Œ", type="primary")
    if not run:
        return

    if not uploads or len(uploads) == 0:
        st.error("è¯·è‡³å°‘ä¸Šä¼  1 ä¸ªæ–‡ä»¶")
        return

    script_path = PROCESSING_TYPES[type_name]
    if not os.path.exists(script_path):
        st.error(f"æ‰¾ä¸åˆ°è„šæœ¬ï¼š{script_path}")
        return

    run_root = os.path.join(WORKSPACE_ROOT, ".app_runs", str(uuid.uuid4()))
    ensure_exists(run_root)

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    results: List[Dict] = []
    progress = st.progress(0)
    status = st.empty()

    for idx, up in enumerate(uploads, start=1):
        status.write(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {idx} / {len(uploads)}ï¼š{up.name}")
        file_dir = os.path.join(run_root, f"file_{idx}")
        saved_input = save_uploaded_file(up, file_dir)
        try:
            out_path, stdout = run_script_with_temp_cwd(script_path, saved_input, file_dir)
        except Exception as e:
            st.error(f"è¿è¡Œè„šæœ¬å¤±è´¥ï¼š{e}")
            st.code(str(e))
            return
        # é¢„è§ˆï¼šæœ€åä¸€ä¸ª Sheet çš„å‰ N è¡Œ
        try:
            df_last, penult_col, _ = load_last_sheet_and_penultimate_column(out_path)
        except Exception as e:
            st.error(f"ç»“æœé¢„è§ˆå¤±è´¥ï¼š{e}")
            return
        results.append({
            "name": up.name,
            "input_path": saved_input,
            "output_path": out_path,
            "last_sheet_df": df_last,
            "penultimate_col": penult_col,
        })
        progress.progress(int(idx / len(uploads) * 0.6 * 100))

    status.write("å•æ–‡ä»¶/åŒæ–‡ä»¶ç»“æœç”Ÿæˆå®Œæˆï¼Œå‡†å¤‡æ¸²æŸ“é¢„è§ˆâ€¦")

    # å±•ç¤ºå•/åŒæ–‡ä»¶ç»“æœä¸ä¸‹è½½
    for i, res in enumerate(results, start=1):
        st.markdown(f"**ç»“æœæ–‡ä»¶ {i}ï¼š{res['name']}**")
        st.dataframe(res["last_sheet_df"].head(preview_rows))
        with open(res["output_path"], "rb") as f:
            st.download_button(
                label=f"ä¸‹è½½ç»“æœ Excelï¼ˆæ–‡ä»¶{i}ï¼‰",
                data=f.read(),
                file_name=os.path.basename(res["output_path"]),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"dl_{i}",
            )

    # è‹¥ä¸ºåŒæ–‡ä»¶ï¼Œåšå¯¹æ¯”
    if len(results) == 2:
        st.divider()
        st.subheader("åŒæ–‡ä»¶å¯¹æ¯”ç»Ÿè®¡")
        try:
            detail_df, summary_df, chart_png, column_avg_df, threshold_df = compare_two_results(
                results[0]["output_path"],
                results[1]["output_path"],
                align_mode=("key" if align_mode == "æŒ‰é”®åˆ—å¯¹é½" else "row"),
                key_column=key_col,
                join_strategy=join_strategy,
                processing_type=type_name,
                ge_threshold=7.0,
                avg_round_decimals=2,
            )
        except Exception as e:
            st.error(f"å¯¹æ¯”å¤±è´¥ï¼š{e}")
            return

        # å±•ç¤ºæ˜ç»†ä¸æ±‡æ€»
        st.markdown("**å¯¹æ¯”æ˜ç»†ï¼ˆå‰Nè¡Œï¼‰**")
        st.dataframe(detail_df.head(preview_rows))

        st.markdown("**æ±‡æ€»ç»Ÿè®¡**")
        st.dataframe(summary_df)

        # å›¾è¡¨æ˜¾ç¤º
        if chart_png:
            chart_caption = "G/SG/S/SB/B æ•°é‡åˆ†å¸ƒ" if type_name == "é—®ç­”æå–" else "G/S/B æ•°é‡åˆ†å¸ƒ"
            st.markdown("**åˆ†å¸ƒå›¾**" if type_name == "é—®ç­”æå–" else "**G/S/B åˆ†å¸ƒå›¾**")
            st.image(chart_png, caption=chart_caption, use_container_width=False)
            st.download_button(
                label="ä¸‹è½½ç»Ÿè®¡å›¾ï¼ˆPNGï¼‰",
                data=chart_png,
                file_name="å¯¹æ¯”ç»Ÿè®¡å›¾.png",
                mime="image/png",
            )
        else:
            st.warning("å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–åŒ…å®‰è£…çŠ¶æ€")

        # åˆ—çº§ç»Ÿè®¡ç»“æœå±•ç¤ºï¼ˆå‡å€¼ & é˜ˆå€¼è®¡æ•°ï¼‰
        st.markdown("**åˆ—çº§å‡å€¼ç»Ÿè®¡ï¼ˆç¬¬2åˆ—è‡³å€’æ•°ç¬¬2åˆ—ï¼‰**")
        st.dataframe(column_avg_df)

        st.markdown("**åˆ—çº§é˜ˆå€¼è®¡æ•°ï¼ˆç¬¬2åˆ—è‡³å€’æ•°ç¬¬2åˆ—ï¼‰**")
        st.dataframe(threshold_df)

        # ç”Ÿæˆå¯¹æ¯”ç»Ÿè®¡ç»“æœ Excel
        compare_dir = os.path.join(run_root, "compare")
        cmp_xlsx = build_comparison_excel(detail_df, summary_df, compare_dir, column_avg_df, threshold_df)
        with open(cmp_xlsx, "rb") as f:
            st.download_button(
                label="ä¸‹è½½å¯¹æ¯”ç»Ÿè®¡ç»“æœ Excel",
                data=f.read(),
                file_name=os.path.basename(cmp_xlsx),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

    progress.progress(100)
    status.write("å¤„ç†å®Œæˆ")


if __name__ == "__main__":
    main_page()


