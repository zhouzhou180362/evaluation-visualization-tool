import os
import io
import shutil
import uuid
import subprocess
from typing import Dict, Tuple, Optional, List

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
from matplotlib import font_manager as fm


# ========= åŸºç¡€é…ç½® =========
WORKSPACE_ROOT = os.path.abspath(os.path.dirname(__file__))

# ç§»é™¤å¯¹å¤–éƒ¨è„šæœ¬çš„ä¾èµ–ï¼Œæ”¹ä¸ºå†…ç½®å¤„ç†é€»è¾‘
PROCESSING_TYPES: Dict[str, str] = {
    "é—®ç­”æå–": "builtin",
    "ç¿»è¯‘æå–": "builtin",
    "è§£é‡Šä»£ç æå–": "builtin",
    "å‘½ä»¤ç›¸å…³æå–": "builtin",
    "ä»£ç ç”Ÿæˆæå–": "builtin",
    "ä»£ç çº é”™æå–": "builtin",
    "ä»£ç è¡¥å…¨æå–": "builtin",
    "è®¡ç®—æœºçŸ¥è¯†æå–": "builtin",
}


def ensure_exists(path: str):
    os.makedirs(path, exist_ok=True)


def ensure_cjk_font():
    """ä¸º Matplotlib è®¾ç½®å¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œé¿å…ä¸­æ–‡æ˜¾ç¤ºä¸ºæ–¹å—ã€‚"""
    try:
        # åœ¨Streamlit Cloudç¯å¢ƒä¸­ä½¿ç”¨æ›´å…¼å®¹çš„å­—ä½“è®¾ç½®
        plt.rcParams["font.sans-serif"] = ["DejaVu Sans", "Arial Unicode MS", "SimHei"]
        plt.rcParams["font.family"] = "sans-serif"
        plt.rcParams["axes.unicode_minus"] = False
    except Exception:
        # å®‰é™å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
        pass


def save_uploaded_file(uploaded_file, dest_dir: str) -> str:
    ensure_exists(dest_dir)
    dest_path = os.path.join(dest_dir, uploaded_file.name)
    with open(dest_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return dest_path


def process_excel_builtin(input_xlsx_path: str, processing_type: str) -> str:
    """
    å†…ç½®å¤„ç†é€»è¾‘ï¼Œç›´æ¥å¤„ç†Excelæ–‡ä»¶è€Œä¸ä¾èµ–å¤–éƒ¨è„šæœ¬
    """
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(input_xlsx_path, engine="openpyxl")

        # æ ¹æ®å¤„ç†ç±»å‹è¿›è¡Œä¸åŒçš„å¤„ç†
        if processing_type == "é—®ç­”æå–":
            # æ¨¡æ‹Ÿé—®ç­”æå–å¤„ç†é€»è¾‘
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
            processed_df = df.copy()
            # æ·»åŠ ä¸€ä¸ªç¤ºä¾‹åˆ—ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥æ ¹æ®å…·ä½“éœ€æ±‚å¤„ç†
            processed_df["å¤„ç†ç»“æœ"] = "å·²å¤„ç†"

        elif processing_type == "ç¿»è¯‘æå–":
            processed_df = df.copy()
            processed_df["ç¿»è¯‘çŠ¶æ€"] = "å¾…ç¿»è¯‘"

        elif processing_type == "è§£é‡Šä»£ç æå–":
            processed_df = df.copy()
            processed_df["ä»£ç è§£é‡Š"] = "éœ€è¦è§£é‡Š"

        elif processing_type == "å‘½ä»¤ç›¸å…³æå–":
            processed_df = df.copy()
            processed_df["å‘½ä»¤çŠ¶æ€"] = "å¾…æ‰§è¡Œ"

        elif processing_type == "ä»£ç ç”Ÿæˆæå–":
            processed_df = df.copy()
            processed_df["ä»£ç ç”Ÿæˆ"] = "å¾…ç”Ÿæˆ"

        elif processing_type == "ä»£ç çº é”™æå–":
            processed_df = df.copy()
            processed_df["ä»£ç çº é”™"] = "å¾…çº é”™"

        elif processing_type == "ä»£ç è¡¥å…¨æå–":
            processed_df = df.copy()
            processed_df["ä»£ç è¡¥å…¨"] = "å¾…è¡¥å…¨"

        elif processing_type == "è®¡ç®—æœºçŸ¥è¯†æå–":
            processed_df = df.copy()
            processed_df["çŸ¥è¯†åˆ†ç±»"] = "å¾…åˆ†ç±»"

        else:
            processed_df = df.copy()
            processed_df["å¤„ç†çŠ¶æ€"] = "å·²å¤„ç†"

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(input_xlsx_path))[0]
        output_dir = os.path.dirname(input_xlsx_path)
        output_path = os.path.join(output_dir, f"{base_name}_multi_sheets.xlsx")

        # ä¿å­˜å¤„ç†åçš„æ–‡ä»¶
        with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
            processed_df.to_excel(writer, sheet_name="å¤„ç†ç»“æœ", index=False)
            # æ·»åŠ åŸå§‹æ•°æ®ä½œä¸ºç¬¬äºŒä¸ªsheet
            df.to_excel(writer, sheet_name="åŸå§‹æ•°æ®", index=False)

        return output_path

    except Exception as e:
        st.error(f"å¤„ç†Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        raise RuntimeError(f"å†…ç½®å¤„ç†å¤±è´¥: {str(e)}")


def run_script_with_temp_cwd(script_path: str, input_xlsx_path: str, run_dir: str, processing_type: str) -> Tuple[str, str]:
    """
    ä¿®æ”¹åçš„å¤„ç†å‡½æ•°ï¼Œä¼˜å…ˆä½¿ç”¨å†…ç½®é€»è¾‘
    """
    ensure_exists(run_dir)
    local_input = os.path.join(run_dir, os.path.basename(input_xlsx_path))
    if os.path.abspath(local_input) != os.path.abspath(input_xlsx_path):
        shutil.copy2(input_xlsx_path, local_input)

    try:
        # ä¼˜å…ˆä½¿ç”¨å†…ç½®å¤„ç†é€»è¾‘
        if script_path == "builtin":
            output_path = process_excel_builtin(local_input, processing_type)
            return output_path, "å†…ç½®å¤„ç†å®Œæˆ"

        # å¦‚æœä»ç„¶éœ€è¦å¤–éƒ¨è„šæœ¬ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        env = os.environ.copy()
        python_exec = env.get("PYTHON_EXECUTABLE", None) or "python3"
        completed = subprocess.run(
            [python_exec, script_path],
            cwd=run_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            check=False,
            text=True,
        )
        stdout = completed.stdout

        # åœ¨ run_dir ä¸­å¯»æ‰¾è¾“å‡º *_multi_sheets*.xlsx
        out_files = [
            os.path.join(run_dir, f)
            for f in os.listdir(run_dir)
            if f.lower().endswith(".xlsx") and "_multi_sheets" in f
        ]
        if not out_files:
            raise RuntimeError(f"è„šæœ¬æœªäº§å‡ºç»“æœ Excelã€‚è¾“å‡ºæ—¥å¿—å¦‚ä¸‹:\n{stdout}")
        # å–ä¿®æ”¹æ—¶é—´æœ€æ–°çš„
        out_files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
        return out_files[0], stdout

    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        raise RuntimeError(f"å¤„ç†å¤±è´¥: {str(e)}")


def load_last_sheet_and_penultimate_column(xlsx_path: str) -> Tuple[pd.DataFrame, str, pd.Series]:
    """
    åŠ è½½ç»“æœ Excel çš„æœ€åä¸€ä¸ª Sheetï¼Œè¿”å› (æœ€åSheetçš„DataFrame, å€’æ•°ç¬¬äºŒåˆ—åˆ—å, è¯¥åˆ—Series)
    è‹¥åˆ—æ•° < 2 åˆ™æŠ›é”™ã€‚
    """
    try:
        xls = pd.ExcelFile(xlsx_path, engine="openpyxl")
    except Exception as e:
        raise RuntimeError(f"è¯»å–ç»“æœ Excel å¤±è´¥ï¼š{e}")

    if not xls.sheet_names:
        raise RuntimeError("ç»“æœ Excel ä¸åŒ…å«ä»»ä½• Sheet")
    last_sheet_name = xls.sheet_names[-1]
    df = pd.read_excel(xls, sheet_name=last_sheet_name, engine="openpyxl")
    if df.shape[1] < 2:
        raise RuntimeError(f"æœ€åä¸€ä¸ª Sheet â€˜{last_sheet_name}â€™ çš„åˆ—æ•°ä¸è¶³ï¼Œæ— æ³•å®šä½å€’æ•°ç¬¬äºŒåˆ—")
    penultimate_col = df.columns[-2]
    return df, penultimate_col, df.iloc[:, -2]


def compare_two_results(
    xlsx1: str,
    xlsx2: str,
    align_mode: str = "row",
    key_column: Optional[str] = None,
    join_strategy: str = "left",
    processing_type: Optional[str] = None,
    ge_threshold: float = 7.0,
    avg_round_decimals: int = 2,
) -> Tuple[pd.DataFrame, pd.DataFrame, bytes, pd.DataFrame, pd.DataFrame]:
    """
    åŸºäºä¸¤ä¸ªç»“æœ Excelï¼ˆæœ€åä¸€ä¸ª Sheet çš„å€’æ•°ç¬¬äºŒåˆ—ï¼‰è¿›è¡Œå¯¹æ¯”ã€‚
    è¿”å›ï¼š(å¯¹æ¯”æ˜ç»† DataFrame, æ±‡æ€»ç»Ÿè®¡ DataFrame, å›¾è¡¨PNGå­—èŠ‚)
    """
    df1, col1_name, s1 = load_last_sheet_and_penultimate_column(xlsx1)
    df2, col2_name, s2 = load_last_sheet_and_penultimate_column(xlsx2)

    detail_rows: List[Dict] = []

    def compare_values(v1, v2) -> Tuple[str, Optional[float], Optional[str]]:
        n1 = pd.to_numeric(pd.Series([v1]), errors="coerce").iloc[0]
        n2 = pd.to_numeric(pd.Series([v2]), errors="coerce").iloc[0]
        abnormal: Optional[str] = None
        if pd.isna(n1) or pd.isna(n2):
            return "N/A", np.nan, "å€¼æ— æ³•è½¬ä¸ºæ•°å€¼æˆ–ç¼ºå¤±"

        diff = float(n1 - n2)

        # ç‰¹æ®Šé€»è¾‘ï¼šé—®ç­”æå– æŒ‰ Excel è§„åˆ™
        if processing_type == "é—®ç­”æå–":
            # åŸå§‹ Excel è§„åˆ™ï¼š
            # =IF(A2=B2,"S",IF(ABS(A2-B2)>1,IF(A2>B2,"A","B"),IF(OR(ABS(A2-B2)=1,ABS(A2-B2)=0),"S"&IF(A2>B2,"A","B"),"B")))
            if n1 == n2:
                base = "S"
            else:
                ad = abs(n1 - n2)
                if ad > 1:
                    base = "A" if n1 > n2 else "B"
                elif ad == 1 or ad == 0:
                    base = "S" + ("A" if n1 > n2 else "B")
                else:
                    base = "B"
            mapping = {"A": "G", "SA": "SG", "S": "S", "SB": "SB", "B": "B"}
            tag = mapping.get(base, "S")
            return tag, diff, abnormal

        # é»˜è®¤é€»è¾‘ï¼šG/S/B
        if n1 > n2:
            tag = "G"
        elif n1 == n2:
            tag = "S"
        else:
            tag = "B"
        return tag, diff, abnormal

    if align_mode == "row":
        len1, len2 = len(df1), len(df2)
        max_len = max(len1, len2)
        for i in range(max_len):
            v1 = s1.iloc[i] if i < len1 else np.nan
            v2 = s2.iloc[i] if i < len2 else np.nan
            tag, diff, abnormal = compare_values(v1, v2)
            if i >= len1 or i >= len2:
                abnormal = (abnormal + "; " if abnormal else "") + "ä¸¤æ–‡ä»¶è¡Œæ•°ä¸ä¸€è‡´"
            detail_rows.append({
                "è¡Œç´¢å¼•": i,
                "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                "å·®å€¼(å€¼1-å€¼2)": diff,
                "æ ‡è®°": tag,
                "å¼‚å¸¸è¯´æ˜": abnormal,
            })
    else:
        if not key_column:
            raise RuntimeError("é€‰æ‹©é”®å¯¹é½æ—¶å¿…é¡»æä¾›é”®åˆ—å")
        if key_column not in df1.columns:
            raise RuntimeError(f"æ–‡ä»¶1ç¼ºå°‘é”®åˆ— â€˜{key_column}â€™")
        if key_column not in df2.columns:
            raise RuntimeError(f"æ–‡ä»¶2ç¼ºå°‘é”®åˆ— â€˜{key_column}â€™")

        a = df1[[key_column]].copy()
        a["__v1"] = s1.values
        b = df2[[key_column]].copy()
        b["__v2"] = s2.values

        # ä¸»ä½“å¯¹é½
        if join_strategy == "inner":
            keys = sorted(set(a[key_column]).intersection(set(b[key_column])))
        else:  # leftï¼ˆä»¥æ–‡ä»¶1ä¸ºä¸»ï¼‰
            keys = list(a[key_column])

        a_map = dict(zip(a[key_column], a["__v1"]))
        b_map = dict(zip(b[key_column], b["__v2"]))

        for k in dict.fromkeys(keys):
            v1 = a_map.get(k, np.nan)
            v2 = b_map.get(k, np.nan)
            tag, diff, abnormal = compare_values(v1, v2)
            if k not in a_map or k not in b_map:
                abnormal = (abnormal + "; " if abnormal else "") + "é”®æœªåŒ¹é…"
            detail_rows.append({
                "é”®": k,
                "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                "å·®å€¼(å€¼1-å€¼2)": diff,
                "æ ‡è®°": tag,
                "å¼‚å¸¸è¯´æ˜": abnormal,
            })

        # ç»Ÿè®¡ inner æƒ…å†µä¸‹æœªèƒ½åŒ¹é…ä½†éœ€è¦è®°ä¸ºå¼‚å¸¸çš„é”®
        if join_strategy == "inner":
            only_in_a = set(a[key_column]) - set(b[key_column])
            for k in sorted(only_in_a):
                v1 = a_map.get(k, np.nan)
                detail_rows.append({
                    "é”®": k,
                    "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": v1,
                    "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": np.nan,
                    "å·®å€¼(å€¼1-å€¼2)": np.nan,
                    "æ ‡è®°": "N/A",
                    "å¼‚å¸¸è¯´æ˜": "é”®æœªåŒ¹é…(ä»…æ–‡ä»¶1)",
                })
            only_in_b = set(b[key_column]) - set(a[key_column])
            for k in sorted(only_in_b):
                v2 = b_map.get(k, np.nan)
                detail_rows.append({
                    "é”®": k,
                    "å€¼1(å€’æ•°ç¬¬äºŒåˆ—)": np.nan,
                    "å€¼2(å€’æ•°ç¬¬äºŒåˆ—)": v2,
                    "å·®å€¼(å€¼1-å€¼2)": np.nan,
                    "æ ‡è®°": "N/A",
                    "å¼‚å¸¸è¯´æ˜": "é”®æœªåŒ¹é…(ä»…æ–‡ä»¶2)",
                })

    detail_df = pd.DataFrame(detail_rows)
    # æ±‡æ€»
    total = len(detail_df)
    # æ±‡æ€»ç»Ÿè®¡ï¼šé—®ç­”æå–åœºæ™¯åŒ…å«SGå’ŒSBï¼Œå…¶ä»–åœºæ™¯æŒ‰G/S/Bèšåˆ
    if processing_type == "é—®ç­”æå–":
        # é—®ç­”æå–åœºæ™¯ï¼šåŒ…å«SGå’ŒSB
        counts = detail_df["æ ‡è®°"].value_counts(dropna=False).reindex(["G", "SG", "S", "SB", "B", "N/A"], fill_value=0)
        summary_df = pd.DataFrame({
            "ç±»åˆ«": ["G", "SG", "S", "SB", "B", "N/A"],
            "æ•°é‡": [int(counts.get(x, 0)) for x in ["G", "SG", "S", "SB", "B", "N/A"]],
        })
        summary_df["å æ¯”"] = summary_df["æ•°é‡"].apply(lambda x: f"{(x / total * 100) if total else 0:.2f}%")
    else:
        # å…¶ä»–åœºæ™¯ï¼šSG/SBå½’å…¥S
        def base_bucket(x: str) -> str:
            if x == "N/A":
                return "N/A"
            if x in ("G", "S", "B"):
                return x
            if x in ("SG", "SB"):
                return "S"
            return x

        counts = detail_df["æ ‡è®°"].map(base_bucket).value_counts(dropna=False).reindex(["G", "S", "B", "N/A"], fill_value=0)
        summary_df = pd.DataFrame({
            "ç±»åˆ«": ["G", "S", "B", "N/A"],
            "æ•°é‡": [int(counts.get(x, 0)) for x in ["G", "S", "B", "N/A"]],
        })
        summary_df["å æ¯”"] = summary_df["æ•°é‡"].apply(lambda x: f"{(x / total * 100) if total else 0:.2f}%")
    # å¯é™„åŠ åŸºç¡€æŒ‡æ ‡
    try:
        numeric_diff = pd.to_numeric(detail_df["å·®å€¼(å€¼1-å€¼2)"], errors="coerce")
        mean1 = pd.to_numeric(detail_df["å€¼1(å€’æ•°ç¬¬äºŒåˆ—)"], errors="coerce").mean()
        mean2 = pd.to_numeric(detail_df["å€¼2(å€’æ•°ç¬¬äºŒåˆ—)"], errors="coerce").mean()
        diff_mean = numeric_diff.mean()
    except Exception:
        mean1 = mean2 = diff_mean = np.nan

    extra_rows = pd.DataFrame([
        {"ç±»åˆ«": "å€¼1å‡å€¼", "æ•°é‡": mean1, "å æ¯”": "-"},
        {"ç±»åˆ«": "å€¼2å‡å€¼", "æ•°é‡": mean2, "å æ¯”": "-"},
        {"ç±»åˆ«": "å·®å€¼å‡å€¼", "æ•°é‡": diff_mean, "å æ¯”": "-"},
    ])
    summary_df = pd.concat([summary_df, extra_rows], ignore_index=True)

    # ç”»å›¾ï¼ˆæŸ±çŠ¶å›¾ G/S/Bï¼‰
    ensure_cjk_font()
    # å›¾è¡¨ï¼šé—®ç­”æå–å±•ç¤º SG/SB ç»†åˆ†ï¼›å…¶ä»–ç±»å‹å±•ç¤º G/S/B
    fig, ax = plt.subplots(figsize=(6, 3))
    if processing_type == "é—®ç­”æå–":
        detailed_counts = detail_df["æ ‡è®°"].value_counts(dropna=False)
        cats = ["G", "SG", "S", "SB", "B"]
        values = [int(detailed_counts.get(c, 0)) for c in cats]
        colors = ["#4CAF50", "#81C784", "#2196F3", "#FFB74D", "#F44336"]
        ax.bar(cats, values, color=colors)
        ax.set_title("G/SG/S/SB/B æ•°é‡åˆ†å¸ƒ")
    else:
        ax.bar(["G", "S", "B"], [counts.get("G", 0), counts.get("S", 0), counts.get("B", 0)], color=["#4CAF50", "#2196F3", "#F44336"])
        ax.set_title("G/S/B æ•°é‡åˆ†å¸ƒ")
    ax.set_ylabel("æ•°é‡")
    buf = io.BytesIO()
    plt.tight_layout()
    fig.savefig(buf, format="png", dpi=200)
    plt.close(fig)
    buf.seek(0)

    # ============== æ–°å¢ï¼šåˆ—çº§ç»Ÿè®¡ï¼ˆç¬¬2åˆ—..å€’æ•°ç¬¬2åˆ—ï¼‰ ==============
    def compute_column_stats(df_a: pd.DataFrame, df_b: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        cols_a = list(df_a.columns)
        cols_b = list(df_b.columns)
        rng_a = cols_a[1:-1] if len(cols_a) >= 3 else []
        rng_b = cols_b[1:-1] if len(cols_b) >= 3 else []
        max_len = max(len(rng_a), len(rng_b))

        mean_rows: List[Dict] = []
        thresh_rows: List[Dict] = []

        for i in range(max_len):
            name_a = rng_a[i] if i < len(rng_a) else None
            name_b = rng_b[i] if i < len(rng_b) else None

            s_a = df_a[name_a] if name_a is not None else pd.Series(dtype=float)
            s_b = df_b[name_b] if name_b is not None else pd.Series(dtype=float)

            num_a = pd.to_numeric(s_a, errors="coerce")
            num_b = pd.to_numeric(s_b, errors="coerce")

            valid_a = num_a.dropna()
            valid_b = num_b.dropna()

            abnormal_notes: List[str] = []
            if name_a is None:
                abnormal_notes.append("æ–‡ä»¶1ç¼ºå°‘å¯¹åº”åˆ—")
            if name_b is None:
                abnormal_notes.append("æ–‡ä»¶2ç¼ºå°‘å¯¹åº”åˆ—")
            if valid_a.empty:
                abnormal_notes.append("æ–‡ä»¶1æ— æœ‰æ•ˆæ•°å€¼")
            if valid_b.empty:
                abnormal_notes.append("æ–‡ä»¶2æ— æœ‰æ•ˆæ•°å€¼")

            mean_a = round(float(valid_a.mean()), avg_round_decimals) if not valid_a.empty else np.nan
            mean_b = round(float(valid_b.mean()), avg_round_decimals) if not valid_b.empty else np.nan
            mean_diff = round(mean_a - mean_b, avg_round_decimals) if not (pd.isna(mean_a) or pd.isna(mean_b)) else np.nan

            mean_rows.append({
                "åˆ—åº": i + 2,
                "æ–‡ä»¶1åˆ—å": name_a,
                "æ–‡ä»¶2åˆ—å": name_b,
                "æ–‡ä»¶1å‡å€¼": mean_a if not pd.isna(mean_a) else "N/A",
                "æ–‡ä»¶2å‡å€¼": mean_b if not pd.isna(mean_b) else "N/A",
                "å·®å€¼(å‡å€¼1-å‡å€¼2)": mean_diff if not pd.isna(mean_diff) else "N/A",
                "å¼‚å¸¸è¯´æ˜": "; ".join(abnormal_notes) if abnormal_notes else None,
            })

            # é˜ˆå€¼è®¡æ•°
            cnt_a = int((valid_a >= ge_threshold).sum()) if not valid_a.empty else 0
            cnt_b = int((valid_b >= ge_threshold).sum()) if not valid_b.empty else 0
            diff_cnt = cnt_a - cnt_b

            # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆç›¸å¯¹äºæœ‰æ•ˆæ•°æ®æ•°é‡ï¼‰
            pct_cnt_a = f"{(cnt_a / len(valid_a) * 100) if len(valid_a) else 0:.2f}%"
            pct_cnt_b = f"{(cnt_b / len(valid_b) * 100) if len(valid_b) else 0:.2f}%"

            thresh_rows.append({
                "åˆ—åº": i + 2,
                "æ–‡ä»¶1åˆ—å": name_a,
                "æ–‡ä»¶2åˆ—å": name_b,
                "é˜ˆå€¼(>=)": ge_threshold,
                "æ–‡ä»¶1è®¡æ•°": cnt_a,
                "æ–‡ä»¶1è®¡æ•°å æ¯”": pct_cnt_a,
                "æ–‡ä»¶2è®¡æ•°": cnt_b,
                "æ–‡ä»¶2è®¡æ•°å æ¯”": pct_cnt_b,
                "å·®å€¼(è®¡æ•°1-è®¡æ•°2)": diff_cnt,
                "å¼‚å¸¸è¯´æ˜": "; ".join(abnormal_notes) if abnormal_notes else None,
            })

        return pd.DataFrame(mean_rows), pd.DataFrame(thresh_rows)

    column_avg_df, threshold_df = compute_column_stats(df1, df2)

    return detail_df, summary_df, buf.read(), column_avg_df, threshold_df


def build_comparison_excel(detail_df: pd.DataFrame, summary_df: pd.DataFrame, save_dir: str,
                           column_avg_df: Optional[pd.DataFrame] = None,
                           threshold_df: Optional[pd.DataFrame] = None) -> str:
    ensure_exists(save_dir)
    out_path = os.path.join(save_dir, "å¯¹æ¯”ç»Ÿè®¡ç»“æœ.xlsx")
    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        detail_df.to_excel(writer, index=False, sheet_name="å¯¹æ¯”æ˜ç»†")
        summary_df.to_excel(writer, index=False, sheet_name="æ±‡æ€»ç»Ÿè®¡")
        if column_avg_df is not None:
            column_avg_df.to_excel(writer, index=False, sheet_name="åˆ—çº§å‡å€¼ç»Ÿè®¡")
        if threshold_df is not None:
            threshold_df.to_excel(writer, index=False, sheet_name="åˆ—çº§é˜ˆå€¼è®¡æ•°")
    return out_path


def main_page():
    st.set_page_config(page_title="è‡ªåŠ¨åŒ–è¯„æµ‹å¯è§†åŒ–å·¥å…·", layout="wide", page_icon="ğŸ“Š")
    st.title("è‡ªåŠ¨åŒ–è¯„æµ‹å¯è§†åŒ–å·¥å…·")

    with st.sidebar:
        st.markdown("**ä½¿ç”¨æµç¨‹**")
        st.markdown("1. é€‰æ‹©å¤„ç†ç±»å‹\n2. ä¸Šä¼  1 æˆ– 2 ä¸ª Excel\n3. é€‰æ‹©å¯¹é½æ–¹å¼ï¼ˆå¯é€‰ï¼‰\n4. ç‚¹å‡»å¼€å§‹å¤„ç†")

    st.subheader("é€‰æ‹©å¤„ç†ç±»å‹")
    type_name = st.selectbox("å¤„ç†ç±»å‹", list(PROCESSING_TYPES.keys()))
    st.caption("æ¯ç§ç±»å‹å°†ä½¿ç”¨å†…ç½®å¤„ç†é€»è¾‘ï¼Œç›´æ¥åœ¨åº”ç”¨ä¸­å¤„ç†Excelæ–‡ä»¶ã€‚")

    st.subheader("ä¸Šä¼ æ–‡ä»¶")
    uploads = st.file_uploader("ä¸Šä¼  1 æˆ– 2 ä¸ª Excel æ–‡ä»¶ (.xlsx)", type=["xlsx"], accept_multiple_files=True)
    if uploads and len(uploads) > 2:
        st.error("æœ€å¤šåªèƒ½ä¸Šä¼  2 ä¸ªæ–‡ä»¶")
        return

    st.subheader("å¯¹é½æ–¹å¼ï¼ˆå¯é€‰å¢å¼ºï¼‰")
    align_mode = st.radio("å¯¹é½æ¨¡å¼", options=["æŒ‰è¡Œåº", "æŒ‰é”®åˆ—å¯¹é½"], index=0, horizontal=True)
    key_col = None
    join_strategy = "left"
    if align_mode == "æŒ‰é”®åˆ—å¯¹é½":
        key_col = st.text_input("é”®åˆ—åï¼ˆä¸¤ä¸ªç»“æœè¡¨çš„æœ€åä¸€ä¸ª Sheet ä¸­éœ€åŒ…å«æ­¤åˆ—ï¼‰")
        join_strategy = st.selectbox("å¯¹é½ç­–ç•¥", options=["left", "inner"], index=0, help="left: ä»¥æ–‡ä»¶1ä¸ºä¸»ï¼›inner: ä»…åŒ¹é…åˆ°çš„é”®ï¼Œä½†æœªåŒ¹é…é”®ä¹Ÿä¼šè®°ä¸ºå¼‚å¸¸è¡Œ")

    st.subheader("å…¶ä»–")
    preview_rows = st.slider("é¢„è§ˆè¡Œæ•°ï¼ˆæœ€åä¸€ä¸ª Sheet æˆ–å¯¹æ¯”æ˜ç»†ï¼‰", min_value=5, max_value=200, value=50, step=5)

    run = st.button("å¼€å§‹å¤„ç†/è¿è¡Œ", type="primary")
    if not run:
        return

    if not uploads or len(uploads) == 0:
        st.error("è¯·è‡³å°‘ä¸Šä¼  1 ä¸ªæ–‡ä»¶")
        return

    script_path = PROCESSING_TYPES[type_name]
    if script_path == "builtin":
        st.info("é€‰æ‹©å†…ç½®å¤„ç†ç±»å‹ï¼Œå°†ç›´æ¥åœ¨åº”ç”¨ä¸­è¿è¡Œå¤„ç†é€»è¾‘ã€‚")
    elif not os.path.exists(script_path):
        st.error(f"æ‰¾ä¸åˆ°è„šæœ¬ï¼š{script_path}")
        return

    run_root = os.path.join(WORKSPACE_ROOT, ".app_runs", str(uuid.uuid4()))
    ensure_exists(run_root)

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    results: List[Dict] = []
    progress = st.progress(0)
    status = st.empty()

    for idx, up in enumerate(uploads, start=1):
        status.write(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {idx} / {len(uploads)}ï¼š{up.name}")
        file_dir = os.path.join(run_root, f"file_{idx}")
        saved_input = save_uploaded_file(up, file_dir)
        try:
            out_path, stdout = run_script_with_temp_cwd(script_path, saved_input, file_dir, type_name)
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ï¼š{e}")
            st.code(str(e))
            return
        # é¢„è§ˆï¼šæœ€åä¸€ä¸ª Sheet çš„å‰ N è¡Œ
        try:
            df_last, penult_col, _ = load_last_sheet_and_penultimate_column(out_path)
        except Exception as e:
            st.error(f"ç»“æœé¢„è§ˆå¤±è´¥ï¼š{e}")
            return
        results.append({
            "name": up.name,
            "input_path": saved_input,
            "output_path": out_path,
            "last_sheet_df": df_last,
            "penultimate_col": penult_col,
        })
        progress.progress(int(idx / len(uploads) * 0.6 * 100))

    status.write("å•æ–‡ä»¶/åŒæ–‡ä»¶ç»“æœç”Ÿæˆå®Œæˆï¼Œå‡†å¤‡æ¸²æŸ“é¢„è§ˆâ€¦")

    # å±•ç¤ºå•/åŒæ–‡ä»¶ç»“æœä¸ä¸‹è½½
    for i, res in enumerate(results, start=1):
        st.markdown(f"**ç»“æœæ–‡ä»¶ {i}ï¼š{res['name']}**")
        st.dataframe(res["last_sheet_df"].head(preview_rows))
        with open(res["output_path"], "rb") as f:
            st.download_button(
                label=f"ä¸‹è½½ç»“æœ Excelï¼ˆæ–‡ä»¶{i}ï¼‰",
                data=f.read(),
                file_name=os.path.basename(res["output_path"]),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"dl_{i}",
            )

    # è‹¥ä¸ºåŒæ–‡ä»¶ï¼Œåšå¯¹æ¯”
    if len(results) == 2:
        st.divider()
        st.subheader("åŒæ–‡ä»¶å¯¹æ¯”ç»Ÿè®¡")
        try:
            detail_df, summary_df, chart_png, column_avg_df, threshold_df = compare_two_results(
                results[0]["output_path"],
                results[1]["output_path"],
                align_mode=("key" if align_mode == "æŒ‰é”®åˆ—å¯¹é½" else "row"),
                key_column=key_col,
                join_strategy=join_strategy,
                processing_type=type_name,
                ge_threshold=7.0,
                avg_round_decimals=2,
            )
        except Exception as e:
            st.error(f"å¯¹æ¯”å¤±è´¥ï¼š{e}")
            return

        # å±•ç¤ºæ˜ç»†ä¸æ±‡æ€»
        st.markdown("**å¯¹æ¯”æ˜ç»†ï¼ˆå‰Nè¡Œï¼‰**")
        st.dataframe(detail_df.head(preview_rows))

        st.markdown("**æ±‡æ€»ç»Ÿè®¡**")
        st.dataframe(summary_df)

        # å›¾è¡¨
        chart_caption = "G/SG/S/SB/B æ•°é‡åˆ†å¸ƒ" if type_name == "é—®ç­”æå–" else "G/S/B æ•°é‡åˆ†å¸ƒ"
        st.markdown("**åˆ†å¸ƒå›¾**" if type_name == "é—®ç­”æå–" else "**G/S/B åˆ†å¸ƒå›¾**")
        st.image(chart_png, caption=chart_caption, use_container_width=False)
        st.download_button(
            label="ä¸‹è½½ç»Ÿè®¡å›¾ï¼ˆPNGï¼‰",
            data=chart_png,
            file_name="å¯¹æ¯”ç»Ÿè®¡å›¾.png",
            mime="image/png",
        )

        # åˆ—çº§ç»Ÿè®¡ç»“æœå±•ç¤ºï¼ˆå‡å€¼ & é˜ˆå€¼è®¡æ•°ï¼‰
        st.markdown("**åˆ—çº§å‡å€¼ç»Ÿè®¡ï¼ˆç¬¬2åˆ—è‡³å€’æ•°ç¬¬2åˆ—ï¼‰**")
        st.dataframe(column_avg_df)

        st.markdown("**åˆ—çº§é˜ˆå€¼è®¡æ•°ï¼ˆç¬¬2åˆ—è‡³å€’æ•°ç¬¬2åˆ—ï¼‰**")
        st.dataframe(threshold_df)

        # ç”Ÿæˆå¯¹æ¯”ç»Ÿè®¡ç»“æœ Excel
        compare_dir = os.path.join(run_root, "compare")
        cmp_xlsx = build_comparison_excel(detail_df, summary_df, compare_dir, column_avg_df, threshold_df)
        with open(cmp_xlsx, "rb") as f:
            st.download_button(
                label="ä¸‹è½½å¯¹æ¯”ç»Ÿè®¡ç»“æœ Excel",
                data=f.read(),
                file_name=os.path.basename(cmp_xlsx),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

    progress.progress(100)
    status.write("å¤„ç†å®Œæˆ")


if __name__ == "__main__":
    main_page()


